{"cells":[{"cell_type":"markdown","metadata":{},"source":["# FixMatch PyTorch Implementation"]},{"cell_type":"markdown","metadata":{},"source":["## 필요한 패키지 다운로드"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4153,"status":"ok","timestamp":1647328277638,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"3olvYBBHShut","outputId":"7a2fe6e4-5eb8-4a42-a598-5e5095debfee"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (0.4.6)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n","You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install colorama"]},{"cell_type":"markdown","metadata":{},"source":["## 필요한 패키지 중 이미 다운 받아진 패키지 부르기"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":1733,"status":"ok","timestamp":1647328279368,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"p4HGUQjvTyb1"},"outputs":[],"source":["import sys, os, copy, random, argparse, math\n","import numpy as np\n","\n","import PIL\n","import PIL.ImageOps\n","import PIL.ImageEnhance\n","import PIL.ImageDraw\n","from PIL import Image\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import LambdaLR\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from torchvision import datasets\n","from torchvision import transforms\n","from colorama import Fore\n","from tqdm import tqdm\n"]},{"cell_type":"markdown","metadata":{},"source":["## Global variable 정의하기\n","#### PARAMETER_MAX, cifar10의 mean, std"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1647328279369,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"6QzixtWaT0CS"},"outputs":[],"source":["PARAMETER_MAX = 10\n","\n","mean_cifar10 = (0.4914, 0.4822, 0.4465)\n","std_cifar10 = (0.2471, 0.2345, 0.2616)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647328279884,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"slW12bm8UL2U"},"outputs":[],"source":["def _float_parameter(v, max_v):\n","    return float(v) * max_v / PARAMETER_MAX\n","\n","\n","def _int_parameter(v, max_v):\n","    return int(v * max_v / PARAMETER_MAX)"]},{"cell_type":"markdown","metadata":{},"source":["## PIL 패키지 내 각종 Data Augmentation 함수 정의\n","#### https://pillow.readthedocs.io/en/stable/reference/ImageOps.html\n","#### https://pillow.readthedocs.io/en/stable/reference/ImageEnhance.html\n"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1647328279884,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"gBHAD6IoT0yK"},"outputs":[],"source":["def AutoContrast(img, **kwargs):\n","    return PIL.ImageOps.autocontrast(img)\n","\n","\n","def Brightness(img, v, max_v, bias=0):\n","    v = _float_parameter(v, max_v) + bias\n","    return PIL.ImageEnhance.Brightness(img).enhance(v)\n","\n","\n","def Color(img, v, max_v, bias=0):\n","    v = _float_parameter(v, max_v) + bias\n","    return PIL.ImageEnhance.Color(img).enhance(v)\n","\n","\n","def Contrast(img, v, max_v, bias=0):\n","    v = _float_parameter(v, max_v) + bias\n","    return PIL.ImageEnhance.Contrast(img).enhance(v)\n","\n","\n","def CutoutAbs(img, v, **kwargs):\n","    w, h = img.size\n","    x0, y0 = np.random.uniform(0, w), np.random.uniform(0, h)\n","    x0, y0 = int(max(0, x0 - v / 2.)), int(max(0, y0 - v / 2.))\n","\n","    x1, y1 = int(min(w, x0 + v)), int(min(h, y0 + v))\n","\n","    xy = (x0, y0, x1, y1)\n","    # gray\n","    color = (127, 127, 127)\n","    img = img.copy()\n","    \n","    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n","    return img\n","\n","\n","def Cutout(img, v, max_v, bias=0):\n","    if v == 0:\n","        return img\n","    v = _float_parameter(v, max_v) + bias\n","    v = int(v * min(img.size))\n","    return CutoutAbs(img, v)\n","\n","\n","def Equalize(img, **kwargs):\n","    return PIL.ImageOps.equalize(img)\n","\n","\n","def Identity(img, **kwargs):\n","    return img\n","\n","\n","def Invert(img, **kwargs):\n","    return PIL.ImageOps.invert(img)\n","\n","def Posterize(img, v, max_v, bias=0):\n","    v = _int_parameter(v, max_v) + bias\n","    return PIL.ImageOps.posterize(img, v)\n","\n","\n","def Rotate(img, v, max_v, bias=0):\n","    v = _int_parameter(v, max_v) + bias\n","    if random.random() < 0.5:\n","        v = -v\n","    return img.rotate(v)\n","\n","\n","def Sharpness(img, v, max_v, bias=0):\n","    v = _float_parameter(v, max_v) + bias\n","    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n","\n","\n","def ShearX(img, v, max_v, bias=0):\n","    v = _float_parameter(v, max_v) + bias\n","    if random.random() < 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n","\n","\n","def ShearY(img, v, max_v, bias=0):\n","    v = _float_parameter(v, max_v) + bias\n","    if random.random() < 0.5:\n","        v = -v\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n","\n","\n","def Solarize(img, v, max_v, bias=0):\n","    v = _int_parameter(v, max_v) + bias\n","    return PIL.ImageOps.solarize(img, 256 - v)\n","\n","\n","def SolarizeAdd(img, v, max_v, bias=0, threshold=128):\n","    v = _int_parameter(v, max_v) + bias\n","    if random.random() < 0.5:\n","        v = -v\n","    img_np = np.array(img).astype(np.int)\n","    img_np = img_np + v\n","    img_np = np.clip(img_np, 0, 255)\n","    img_np = img_np.astype(np.uint8)\n","    img = Image.fromarray(img_np)\n","    return PIL.ImageOps.solarize(img, threshold)\n","\n","\n","def TranslateX(img, v, max_v, bias=0):\n","    v = _float_parameter(v, max_v) + bias\n","    if random.random() < 0.5:\n","        v = -v\n","    v = int(v * img.size[0])\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n","\n","\n","def TranslateY(img, v, max_v, bias=0):\n","    v = _float_parameter(v, max_v) + bias\n","    if random.random() < 0.5:\n","        v = -v\n","    v = int(v * img.size[1])\n","    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))"]},{"cell_type":"markdown","metadata":{},"source":["## FixMatch 내 RandAugment를 사용하기 위한 PIL 기반 각종 Augmentation 정의"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647328279885,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"pdfdIvkWUQXY"},"outputs":[],"source":["def fixmatch_augment_pool():\n","    # FixMatch paper\n","    augs = [(AutoContrast, None, None),\n","            (Brightness, 0.9, 0.05),\n","            (Color, 0.9, 0.05),\n","            (Contrast, 0.9, 0.05),\n","            (Equalize, None, None),\n","            (Identity, None, None),\n","            (Posterize, 4, 4),\n","            (Rotate, 30, 0),\n","            (Sharpness, 0.9, 0.05),\n","            (ShearX, 0.3, 0),\n","            (ShearY, 0.3, 0),\n","            (Solarize, 256, 0),\n","            (TranslateX, 0.3, 0),\n","            (TranslateY, 0.3, 0)]\n","    return augs"]},{"cell_type":"markdown","metadata":{},"source":["## RandAugment를 위한 class 정의"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["class RandAugmentMC(object):\n","    def __init__(self, n, m):\n","        assert n >= 1\n","        assert 1 <= m <= 10\n","        \n","        self.n = n\n","        self.m = m\n","        self.augment_pool = fixmatch_augment_pool()\n","\n","    def __call__(self, img):\n","        ops = random.choices(self.augment_pool, k=self.n)\n","        # self.augment_pool 내 n개를 선택\n","        # 순차적으로 augmentation 기법 추출 후 적용\n","        for op, max_v, bias in ops:\n","            v = np.random.randint(1, self.m)\n","            if random.random() < 0.5:\n","                img = op(img, v=v, max_v=max_v, bias=bias)\n","\n","        # 최종적으로 CutOut Augmentation 진행\n","        img = CutoutAbs(img, int(32*0.5))\n","        return img"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1647328279885,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"UQlTwYXAUQpv"},"outputs":[],"source":["class CIFAR10_SSL(datasets.CIFAR10):\n","    def __init__(self, root, indexs, train=True,\n","                transform=None, target_transform=None,\n","                download=False):\n","        super(CIFAR10_SSL, self).__init__(\n","            root, train=train, transform=transform,\n","            target_transform=target_transform, download=download\n","        )\n","\n","        if indexs is not None:\n","            self.data = self.data[indexs]\n","            self.targets = np.array(self.targets)[indexs]\n","    \n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        \n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","        \n","        return img, target"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1647328279885,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"N0xtM10qUQsR"},"outputs":[],"source":["# Mixmatch의 transform twice\n","class TransformFixMatch(object):\n","    def __init__(self, mean=mean_cifar10, std=std_cifar10):\n","        self.weak_transform = transforms.Compose([\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomCrop(size=32,\n","                                padding=int(32*0.125),\n","                                padding_mode='reflect')\n","        ])\n","\n","        self.strong_transform = transforms.Compose([\n","            transforms.RandomHorizontalFlip(),\n","            transforms.RandomCrop(size=32,\n","                                padding=int(32*0.125),\n","                                padding_mode='reflect'),\n","            RandAugmentMC(n=2, m=10)\n","            # 기존 weak augmentation에 추가적으로 픽셀 값 왜곡과 같은 Strong augmentation 적용\n","        ])\n","\n","        self.normalize = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=mean, std=std)\n","        ]) # NHWC -> NCHW / 평균, 표준편차를 사용한 표준화\n","    \n","    def __call__(self, x):\n","        weak = self.weak_transform(x)\n","        strong = self.strong_transform(x)\n","\n","        return self.normalize(weak), self.normalize(strong)"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1647328279886,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"OZGgVTRhUQu9"},"outputs":[],"source":["# MixMatch 코드 내 split 함수와 동일\n","def split_labeled_unlabeled(args, labels):\n","    label_per_class = args.n_labeled // args.n_classes\n","    labels = np.array(labels, dtype=int)\n","    indice_labeled, indice_unlabeled, indice_val = [], [], []\n","\n","    for i in range(10):\n","        indice_tmp = np.where(labels==i)[0]\n","\n","        indice_labeled.extend(indice_tmp[: label_per_class])\n","        indice_unlabeled.extend(indice_tmp[label_per_class: -500])\n","        indice_val.extend(indice_tmp[-500: ])\n","    \n","    for i in [indice_labeled, indice_unlabeled, indice_val]:\n","        np.random.shuffle(i)\n","    \n","    return np.array(indice_labeled), np.array(indice_unlabeled), np.array(indice_val)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1647328279886,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"BW-EzldfUQxR"},"outputs":[],"source":["def get_cifar10(args, data_dir):\n","    transform_labeled = transforms.Compose([\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomCrop(size=32, padding=int(32*0.125), padding_mode='reflect'),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=mean_cifar10, std=std_cifar10)\n","    ])\n","\n","    transform_val = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=mean_cifar10, std=std_cifar10)\n","    ])\n","\n","    base_dataset = datasets.CIFAR10(data_dir, train=True, download=True)\n","\n","    indice_labeled, indice_unlabeled, indice_val = split_labeled_unlabeled(args, base_dataset.targets)\n","\n","    # labeled dataset에 대해서는 transform_labeled augmentation 만 적용\n","    labeled_dataset = CIFAR10_SSL(\n","        data_dir, indice_labeled, train=True,\n","        transform=transform_labeled\n","    )\n","\n","    # Unlabeled dataset에 대해서는 transform_labeled augmentation 및 strong augmentation 동시 적용\n","    unlabeled_dataset = CIFAR10_SSL(\n","        data_dir, indice_unlabeled, train=True,\n","        transform=TransformFixMatch(mean=mean_cifar10, std=std_cifar10)\n","    )\n","\n","    # validation, test dataset에 대해서는 ToTensor & Normalization transformation 만 적용\n","    val_dataset = CIFAR10_SSL(\n","        data_dir, indice_val, train=True, transform=transform_val, download=False\n","    )\n","\n","    test_dataset = datasets.CIFAR10(\n","        data_dir, train=False, transform=transform_val, download=False\n","    )\n","    return labeled_dataset, unlabeled_dataset, val_dataset, test_dataset"]},{"cell_type":"markdown","metadata":{},"source":["## WideResNet (MixMatch 와 동일)"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":497,"status":"ok","timestamp":1647328280379,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"Cu8-zR_HUQz1"},"outputs":[],"source":["class BasicBlock(nn.Module):\n","    def __init__(self, in_planes, out_planes, stride, dropRate=0.0, activate_before_residual=False):\n","        super(BasicBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes, momentum=0.001)\n","        self.relu1 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n","        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_planes, momentum=0.001)\n","        self.relu2 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n","        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        self.droprate = dropRate\n","        self.equalInOut = (in_planes == out_planes)\n","        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n","                               padding=0, bias=False) or None\n","        self.activate_before_residual = activate_before_residual\n","    def forward(self, x):\n","        if not self.equalInOut and self.activate_before_residual == True:\n","            x = self.relu1(self.bn1(x))\n","        else:\n","            out = self.relu1(self.bn1(x))\n","        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, training=self.training)\n","        out = self.conv2(out)\n","        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n","\n","class NetworkBlock(nn.Module):\n","    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0, activate_before_residual=False):\n","        super(NetworkBlock, self).__init__()\n","        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual)\n","    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual):\n","        layers = []\n","        for i in range(int(nb_layers)):\n","            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate, activate_before_residual))\n","        return nn.Sequential(*layers)\n","    def forward(self, x):\n","        return self.layer(x)\n","\n","class WideResNet(nn.Module):\n","    def __init__(self, num_classes, depth=28, widen_factor=2, dropRate=0.0):\n","        super(WideResNet, self).__init__()\n","        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n","        assert((depth - 4) % 6 == 0)\n","        n = (depth - 4) / 6\n","        block = BasicBlock\n","        # 1st conv before any network block\n","        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        # 1st block\n","        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate, activate_before_residual=True)\n","        # 2nd block\n","        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n","        # 3rd block\n","        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n","        # global average pooling and classifier\n","        self.bn1 = nn.BatchNorm2d(nChannels[3], momentum=0.001)\n","        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n","        self.fc = nn.Linear(nChannels[3], num_classes)\n","        self.nChannels = nChannels[3]\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                nn.init.xavier_normal_(m.weight.data)\n","                m.bias.data.zero_()\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.block1(out)\n","        out = self.block2(out)\n","        out = self.block3(out)\n","        out = self.relu(self.bn1(out))\n","        out = F.avg_pool2d(out, 8)\n","        out = out.view(-1, self.nChannels)\n","        return self.fc(out)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1647328280379,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"J8MGfe4KUQ3t"},"outputs":[],"source":["class WeightEMA(object): # EMA=Exponential Moving Average\n","    def __init__(self, model, decay):\n","        self.ema = copy.deepcopy(model)\n","        self.ema.eval()\n","\n","        self.decay = decay\n","\n","        self.ema_has_module = hasattr(self.ema, 'module')\n","\n","        self.param_keys = [k for k, _ in self.ema.named_parameters()]\n","        self.buffer_keys = [k for k, _ in self.ema.named_buffers()]\n","        for p in self.ema.parameters():\n","            p.requires_grad_(False)\n","\n","    # summary: ema_params_new = self.decay*ema_params_old + (1-self.decay)*params\n","    # MixMatch와 hyperparameter 이름만 변경\n","    def step(self, model):\n","        needs_module = hasattr(model, 'module') and not self.ema_has_module\n","        with torch.no_grad():\n","            msd = model.state_dict()\n","            esd = self.ema.state_dict()\n","            for k in self.param_keys:\n","                if needs_module:\n","                    j = 'module.' + k\n","                else:\n","                    j = k\n","                model_v = msd[j].detach()\n","                ema_v = esd[k]\n","                esd[k].copy_(ema_v * self.decay + (1. - self.decay) * model_v)\n","\n","            for k in self.buffer_keys:\n","                if needs_module:\n","                    j = 'module.' + k\n","                else:\n","                    j = k\n","                esd[k].copy_(msd[j])"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1647328280379,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"x7_m766lVDNu"},"outputs":[],"source":["def accuracy(output, target, topk=(1, )):\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        if k == 1:\n","            correct_k = correct[:k].view(-1).float().sum(0)\n","        if k > 1:\n","            correct_k = correct[:k].float().sum(0).sum(0)\n","        acc = correct_k.mul_(100.0 / batch_size)\n","        acc = acc.detach().cpu().numpy()\n","        res.append(acc)\n","    return res"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1647328280380,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"Di-FhnXPVDQw"},"outputs":[],"source":["def get_tqdm_config(total, leave=True, color='white'):\n","    fore_colors = {\n","        'red': Fore.LIGHTRED_EX,\n","        'green': Fore.LIGHTGREEN_EX,\n","        'yellow': Fore.LIGHTYELLOW_EX,\n","        'blue': Fore.LIGHTBLUE_EX,\n","        'magenta': Fore.LIGHTMAGENTA_EX,\n","        'cyan': Fore.LIGHTCYAN_EX,\n","        'white': Fore.LIGHTWHITE_EX,\n","    }\n","    return {\n","        'file': sys.stdout,\n","        'total': total,\n","        'desc': \" \",\n","        'dynamic_ncols': True,\n","        'bar_format':\n","            \"{l_bar}%s{bar}%s| [{elapsed}<{remaining}, {rate_fmt}{postfix}]\" % (fore_colors[color], Fore.RESET),\n","        'leave': leave\n","    }"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1647328280380,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"UwHulI5UVDT8"},"outputs":[],"source":["def get_cosine_schedule_with_warmup(\n","    optimizer, num_warmup_steps, num_training_steps,\n","    num_cycles=7.0/16.0, last_epoch=-1\n","    ):\n","    def _lr_lambda(current_step):\n","        if current_step < num_warmup_steps:\n","            return float(current_step)/float(max(1, num_warmup_steps))\n","        \n","        no_progress = float(current_step-num_warmup_steps)/\\\n","            (float(max(1, num_training_steps-num_warmup_steps)))\n","        return max(0.0, math.cos(math.pi*num_cycles*no_progress))\n","    \n","    return LambdaLR(optimizer, _lr_lambda, last_epoch)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<img src='image/img7.png' width='800'></img>"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":263,"status":"ok","timestamp":1647328280640,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"0GJwI58MVDWu"},"outputs":[],"source":["class FixMatchTrainer():\n","    def __init__(self, args):\n","        self.args = args\n","\n","        # root_dir = '/content/FixMatch' # PROJECT directory\n","        root_dir = './FixMatch'\n","        data_dir = os.path.join(root_dir, 'data')\n","\n","        self.experiment_dir = os.path.join(root_dir, 'results') # 학습된 모델을 저장할 폴더 경로 정의 및 폴더 생성\n","        os.makedirs(self.experiment_dir, exist_ok=True)\n","\n","        name_exp = \"_\".join([str(self.args.n_labeled), str(self.args.T)]) # 주요 하이퍼 파라미터로 폴더 저장 경로 지정 \n","        self.experiment_dir = os.path.join(self.experiment_dir, name_exp)\n","        os.makedirs(self.experiment_dir, exist_ok=True)\n","\n","        print(\"==> Preparing CIFAR10 dataset\")\n","        labeled_set, unlabeled_set, _, _= get_cifar10(self.args, data_dir=data_dir)\n","        \n","        # RandomSampler: DataLoader(shuffle=True) 와 동일한 역할\n","        # SequentialSampler: DataLoader(shuffle=False) 와 동일한 역할\n","\n","        # DataLoader 내 num_workers 옵션에 대한 사설\n","        # Window10는 다중 CPU 코어 사용 시 순차적으로 작동 시작\n","        # Linux(Ubuntu, CentOS) 계열은 동시에 CPU 코어 작동을 시작 가능\n","        # (Windows10+PyTorch)를 사용해 Deep Learning 모델 학습 시 num_workers=0을 사용하는 것을 권유\n","        # (Linux계열 운영체제+PyTorch)를 사용해 Deep Learning 모델 학습 시 CPU&GPU 사용량이 최대가 될 수 있도록 num_workers 조정 권유\n","        self.labeled_loader = DataLoader(\n","            labeled_set,\n","            sampler=RandomSampler(labeled_set),\n","            batch_size=self.args.batch_size,\n","            num_workers=0,\n","            drop_last=True\n","        )\n","\n","        self.unlabeled_loader = DataLoader(\n","            unlabeled_set,\n","            sampler=RandomSampler(unlabeled_set),\n","            batch_size=self.args.batch_size,\n","            num_workers=0,\n","            drop_last=True\n","        )\n","\n","        # Build WideResNet\n","        print(\"==> Preparing WideResNet\")\n","        self.model = WideResNet(self.args.n_classes).to(self.args.cuda)\n","        self.model.zero_grad()\n","\n","        self.criterion = torch.nn.CrossEntropyLoss().to(self.args.cuda)\n","\n","        # Hyperparamters\n","        no_decay = ['bias', 'bn']\n","        grouped_parameters = [\n","            {'params': [p for n, p in self.model.named_parameters() if not any(\n","                nd in n for nd in no_decay)], 'weight_decay': self.args.weight_decay},\n","            {'params': [p for n, p in self.model.named_parameters() if any(\n","                nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ] # params의 이름 내 bias, bn이 들어가지 않는 경우에만 weight_decay 적용\n","        self.optimizer = torch.optim.SGD(grouped_parameters, lr=self.args.lr,\n","                            momentum=0.9, nesterov=self.args.nesterov)\n","\n","        # Learning scheduler의 경우 사용이 까다로움\n","        # 특정 scheduler는 각각 iteration 마다 step을 진행\n","        # 또 다른 scheduler그룹은 한 epoch 종료 후 step 진행\n","        # 아래 Documentation 에서 사용할 lr_scheduler에 대한 설명을 정확히 읽고 사용\n","        # https://pytorch.org/docs/stable/optim.html\n","        self.scheduler = get_cosine_schedule_with_warmup(self.optimizer,\n","                                                    self.args.warmup,\n","                                                    self.args.total_steps)\n","        \n","        if self.args.use_ema:\n","            self.ema_model = WeightEMA(self.model, self.args.ema_decay)\n","        \n","        self.writer = SummaryWriter(self.experiment_dir)\n","\n","    def train(self, epoch):\n","        losses_t, losses_x, losses_u, mask_probs = 0.0, 0.0, 0.0, 0.0\n","        \n","        self.model.train()\n","        iter_labeled = iter(self.labeled_loader)\n","        iter_unlabeled = iter(self.unlabeled_loader)\n","\n","        with tqdm(**get_tqdm_config(total=self.args.eval_step,\n","                leave=True, color='blue')) as pbar:\n","            for batch_idx in range(self.args.eval_step):\n","                # 왜 try-except 문을 사용하나?\n","                # 코드 작성 후 iter&next가 정확히 작용하지 않는 경우가 있음을 확인\n","                # 다시 iter_labeled, iter_unlabeled를 정의해 학습에 문제가 없도록 다시 선언\n","                try:\n","                    inputs_x, targets_x = next(iter_labeled)\n","                except:\n","                    iter_labeled = iter(self.labeled_loader)\n","                    inputs_x, targets_x = next(iter_labeled)\n","                real_B = inputs_x.size(0)\n","\n","                try:\n","                    (inputs_u_w, inputs_u_s), _ = next(iter_unlabeled)\n","                except:\n","                    iter_unlabeled = iter(self.unlabeled_loader)\n","                    (inputs_u_w, inputs_u_s), _ = next(iter_unlabeled)\n","                \n","                inputs = torch.cat((inputs_x, inputs_u_w, inputs_u_s), dim=0).to(self.args.cuda)\n","                targets_x = targets_x.to(self.args.cuda)\n","\n","                logits = self.model(inputs)\n","\n","                logits_x = logits[:real_B]\n","                logits_u_w, logits_u_s = logits[real_B:].chunk(2)\n","                del(logits)\n","\n","                # Labeled loss\n","                loss_x = F.cross_entropy(logits_x, targets_x, reduction='mean')\n","\n","                # Unlabeled loss\n","                # Unlabeled 데이터에 대한 로짓 산출 및 Temparature hyperparameter를 사용한 Sharpening\n","                # Pseudo label 생성\n","                pseudo_labels = torch.softmax(logits_u_w.detach()/self.args.T, dim=-1)\n","                max_prob, targets_u = torch.max(pseudo_labels, dim=-1) # (max, max_indices)\n","                mask = max_prob.ge(self.args.threshold).float() # input >= other element wise \n","                # max_prob >= thr -> mask = True\n","                # max < thr -> maks = False\n","\n","                # Pseudo label 과 strong augmentation된 이미지에서 산출된 logit 사이 cross_entropy 계산\n","                loss_u = (F.cross_entropy(logits_u_s, targets_u, reduction='none')*mask).mean()\n","\n","                # Total loss\n","                loss = loss_x + self.args.lambda_u * loss_u \n","                loss.backward()\n","                self.optimizer.step()\n","                self.scheduler.step()\n","                if self.args.use_ema:\n","                    self.ema_model.step(self.model)\n","                \n","                self.model.zero_grad()\n","\n","                losses_x += loss_x.item()\n","                losses_u += loss_u.item()\n","                losses_t += loss.item()\n","                mask_probs += max_prob.mean().item()\n","\n","                self.writer.add_scalars(\n","                    'Training steps', {\n","                        'Total_loss': losses_t/(batch_idx+1),\n","                        'Labeled_loss':losses_x/(batch_idx+1),\n","                        'Unlabeled_loss':losses_u/(batch_idx+1),\n","                        'Mask probs': mask_probs/(batch_idx+1)\n","                    }, global_step=epoch*self.args.batch_size+batch_idx\n","                )\n","\n","                pbar.set_description(\n","                    '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n","                        (batch_idx+1), self.args.eval_step,\n","                        losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n","                    )\n","                )\n","                pbar.update(1)\n","\n","            pbar.set_description(\n","                '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n","                    epoch, self.args.epochs,\n","                    losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n","                )\n","            )\n","        return losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1647328280640,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"k-qr4I-2XwBJ"},"outputs":[],"source":["def FixMatch_parser():\n","    parser = argparse.ArgumentParser(description=\"FixMatch PyTorch Implementation for LG Electornics education\")\n","    \n","    # method arguments\n","    parser.add_argument('--n-labeled', type=int, default=3000)\n","    parser.add_argument('--n-classes', type=int, default=10)\n","    parser.add_argument(\"--expand-labels\", action=\"store_true\",\n","                        help=\"expand labels to fit eval steps\")\n","\n","    # training hyperparameters\n","    parser.add_argument('--batch-size', type=int, default=64)\n","    parser.add_argument('--total-steps', default=2**20, type=int)\n","    parser.add_argument('--eval-step', type=int, default=1024)\n","    parser.add_argument('--lr', type=float, default=0.03)\n","    parser.add_argument('--weight-decay', type=float, default=5e-4)\n","    parser.add_argument('--nesterov', action='store_true', default=True)\n","    parser.add_argument('--warmup', type=float, default=0.0)\n","\n","    parser.add_argument('--use-ema', action='store_true', default=True)\n","    parser.add_argument('--ema-decay', type=float, default=0.999)\n","\n","    parser.add_argument('--mu', type=int, default=7)\n","    parser.add_argument('--T', type=float, default=1.0)\n","\n","    parser.add_argument('--threshold', type=float, default=0.95)\n","    parser.add_argument('--lambda-u', type=float, default=1.0)\n","    return parser"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1647328280640,"user":{"displayName":"‍조용원[ 대학원석·박사통합과정수료연구(재학) / 산업경영공학과 ]","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikNPWH5D7OGgRhnXtOABasxCE9Df06P_LCQGk4=s64","userId":"06670976543419023521"},"user_tz":-540},"id":"_z6O-zHBXwIa"},"outputs":[{"name":"stdout","output_type":"stream","text":["==> Preparing CIFAR10 dataset\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./FixMatch/data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:12<00:00, 13243014.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./FixMatch/data/cifar-10-python.tar.gz to ./FixMatch/data\n","==> Preparing WideResNet\n","[Train(   1/  100)-Total: 1.242|Labeled: 1.198|Unlabeled: 0.044]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.34it/s]\n","[Train(   2/  100)-Total: 0.778|Labeled: 0.618|Unlabeled: 0.160]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.41it/s]\n","[Train(   3/  100)-Total: 0.625|Labeled: 0.364|Unlabeled: 0.262]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.36it/s]\n","[Train(   4/  100)-Total: 0.556|Labeled: 0.240|Unlabeled: 0.316]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.31it/s]\n","[Train(   5/  100)-Total: 0.508|Labeled: 0.177|Unlabeled: 0.331]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(   6/  100)-Total: 0.490|Labeled: 0.145|Unlabeled: 0.344]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.37it/s]\n","[Train(   7/  100)-Total: 0.462|Labeled: 0.116|Unlabeled: 0.346]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.33it/s]\n","[Train(   8/  100)-Total: 0.456|Labeled: 0.106|Unlabeled: 0.349]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(   9/  100)-Total: 0.443|Labeled: 0.100|Unlabeled: 0.343]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.34it/s]\n","[Train(  10/  100)-Total: 0.432|Labeled: 0.088|Unlabeled: 0.343]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.33it/s]\n","[Train(  11/  100)-Total: 0.431|Labeled: 0.087|Unlabeled: 0.345]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  12/  100)-Total: 0.423|Labeled: 0.082|Unlabeled: 0.341]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.36it/s]\n","[Train(  13/  100)-Total: 0.408|Labeled: 0.078|Unlabeled: 0.330]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.35it/s]\n","[Train(  14/  100)-Total: 0.412|Labeled: 0.075|Unlabeled: 0.337]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.36it/s]\n","[Train(  15/  100)-Total: 0.405|Labeled: 0.068|Unlabeled: 0.337]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.35it/s]\n","[Train(  16/  100)-Total: 0.404|Labeled: 0.067|Unlabeled: 0.336]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.33it/s]\n","[Train(  17/  100)-Total: 0.401|Labeled: 0.067|Unlabeled: 0.334]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.36it/s]\n","[Train(  18/  100)-Total: 0.395|Labeled: 0.063|Unlabeled: 0.332]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.36it/s]\n","[Train(  19/  100)-Total: 0.392|Labeled: 0.065|Unlabeled: 0.328]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.32it/s]\n","[Train(  20/  100)-Total: 0.390|Labeled: 0.060|Unlabeled: 0.329]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.35it/s]\n","[Train(  21/  100)-Total: 0.388|Labeled: 0.061|Unlabeled: 0.327]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.38it/s]\n","[Train(  22/  100)-Total: 0.381|Labeled: 0.056|Unlabeled: 0.325]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  23/  100)-Total: 0.376|Labeled: 0.058|Unlabeled: 0.318]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  24/  100)-Total: 0.378|Labeled: 0.054|Unlabeled: 0.324]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.24it/s]\n","[Train(  25/  100)-Total: 0.374|Labeled: 0.053|Unlabeled: 0.321]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  26/  100)-Total: 0.376|Labeled: 0.054|Unlabeled: 0.322]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  27/  100)-Total: 0.375|Labeled: 0.052|Unlabeled: 0.323]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.26it/s]\n","[Train(  28/  100)-Total: 0.375|Labeled: 0.052|Unlabeled: 0.322]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.27it/s]\n","[Train(  29/  100)-Total: 0.370|Labeled: 0.051|Unlabeled: 0.318]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  30/  100)-Total: 0.370|Labeled: 0.051|Unlabeled: 0.319]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  31/  100)-Total: 0.371|Labeled: 0.049|Unlabeled: 0.322]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.32it/s]\n","[Train(  32/  100)-Total: 0.369|Labeled: 0.050|Unlabeled: 0.319]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.25it/s]\n","[Train(  33/  100)-Total: 0.370|Labeled: 0.049|Unlabeled: 0.321]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.26it/s]\n","[Train(  34/  100)-Total: 0.366|Labeled: 0.049|Unlabeled: 0.317]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  35/  100)-Total: 0.362|Labeled: 0.045|Unlabeled: 0.317]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  36/  100)-Total: 0.363|Labeled: 0.046|Unlabeled: 0.317]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.32it/s]\n","[Train(  37/  100)-Total: 0.365|Labeled: 0.047|Unlabeled: 0.318]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.25it/s]\n","[Train(  38/  100)-Total: 0.363|Labeled: 0.046|Unlabeled: 0.317]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  39/  100)-Total: 0.360|Labeled: 0.046|Unlabeled: 0.314]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.27it/s]\n","[Train(  40/  100)-Total: 0.361|Labeled: 0.044|Unlabeled: 0.317]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  41/  100)-Total: 0.361|Labeled: 0.046|Unlabeled: 0.315]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.27it/s]\n","[Train(  42/  100)-Total: 0.362|Labeled: 0.044|Unlabeled: 0.318]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.29it/s]\n","[Train(  43/  100)-Total: 0.357|Labeled: 0.044|Unlabeled: 0.313]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  44/  100)-Total: 0.358|Labeled: 0.043|Unlabeled: 0.315]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  45/  100)-Total: 0.352|Labeled: 0.043|Unlabeled: 0.309]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.27it/s]\n","[Train(  46/  100)-Total: 0.362|Labeled: 0.046|Unlabeled: 0.316]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.29it/s]\n","[Train(  47/  100)-Total: 0.364|Labeled: 0.043|Unlabeled: 0.321]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.29it/s]\n","[Train(  48/  100)-Total: 0.352|Labeled: 0.041|Unlabeled: 0.312]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.26it/s]\n","[Train(  49/  100)-Total: 0.358|Labeled: 0.044|Unlabeled: 0.314]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.26it/s]\n","[Train(  50/  100)-Total: 0.360|Labeled: 0.041|Unlabeled: 0.319]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  51/  100)-Total: 0.358|Labeled: 0.045|Unlabeled: 0.313]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.32it/s]\n","[Train(  52/  100)-Total: 0.351|Labeled: 0.042|Unlabeled: 0.310]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  53/  100)-Total: 0.355|Labeled: 0.040|Unlabeled: 0.315]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  54/  100)-Total: 0.360|Labeled: 0.043|Unlabeled: 0.317]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.36it/s]\n","[Train(  55/  100)-Total: 0.355|Labeled: 0.040|Unlabeled: 0.315]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  56/  100)-Total: 0.352|Labeled: 0.041|Unlabeled: 0.312]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.32it/s]\n","[Train(  57/  100)-Total: 0.351|Labeled: 0.040|Unlabeled: 0.312]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.29it/s]\n","[Train(  58/  100)-Total: 0.352|Labeled: 0.042|Unlabeled: 0.310]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.29it/s]\n","[Train(  59/  100)-Total: 0.350|Labeled: 0.040|Unlabeled: 0.310]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  60/  100)-Total: 0.352|Labeled: 0.039|Unlabeled: 0.313]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  61/  100)-Total: 0.356|Labeled: 0.041|Unlabeled: 0.315]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.33it/s]\n","[Train(  62/  100)-Total: 0.352|Labeled: 0.041|Unlabeled: 0.311]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.24it/s]\n","[Train(  63/  100)-Total: 0.350|Labeled: 0.041|Unlabeled: 0.309]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.27it/s]\n","[Train(  64/  100)-Total: 0.351|Labeled: 0.040|Unlabeled: 0.311]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.31it/s]\n","[Train(  65/  100)-Total: 0.355|Labeled: 0.040|Unlabeled: 0.315]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  66/  100)-Total: 0.353|Labeled: 0.039|Unlabeled: 0.314]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.32it/s]\n","[Train(  67/  100)-Total: 0.348|Labeled: 0.039|Unlabeled: 0.309]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.33it/s]\n","[Train(  68/  100)-Total: 0.353|Labeled: 0.038|Unlabeled: 0.314]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  69/  100)-Total: 0.351|Labeled: 0.039|Unlabeled: 0.312]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.29it/s]\n","[Train(  70/  100)-Total: 0.353|Labeled: 0.038|Unlabeled: 0.315]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.25it/s]\n","[Train(  71/  100)-Total: 0.350|Labeled: 0.037|Unlabeled: 0.313]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.26it/s]\n","[Train(  72/  100)-Total: 0.349|Labeled: 0.038|Unlabeled: 0.311]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  73/  100)-Total: 0.347|Labeled: 0.037|Unlabeled: 0.310]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  74/  100)-Total: 0.350|Labeled: 0.039|Unlabeled: 0.310]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.31it/s]\n","[Train(  75/  100)-Total: 0.349|Labeled: 0.038|Unlabeled: 0.311]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  76/  100)-Total: 0.343|Labeled: 0.037|Unlabeled: 0.306]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  77/  100)-Total: 0.347|Labeled: 0.037|Unlabeled: 0.309]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  78/  100)-Total: 0.352|Labeled: 0.038|Unlabeled: 0.314]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.33it/s]\n","[Train(  79/  100)-Total: 0.346|Labeled: 0.040|Unlabeled: 0.306]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.32it/s]\n","[Train(  80/  100)-Total: 0.349|Labeled: 0.036|Unlabeled: 0.313]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.31it/s]\n","[Train(  81/  100)-Total: 0.342|Labeled: 0.036|Unlabeled: 0.306]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.31it/s]\n","[Train(  82/  100)-Total: 0.345|Labeled: 0.038|Unlabeled: 0.306]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  83/  100)-Total: 0.343|Labeled: 0.036|Unlabeled: 0.307]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.33it/s]\n","[Train(  84/  100)-Total: 0.341|Labeled: 0.036|Unlabeled: 0.305]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.31it/s]\n","[Train(  85/  100)-Total: 0.348|Labeled: 0.036|Unlabeled: 0.312]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.34it/s]\n","[Train(  86/  100)-Total: 0.347|Labeled: 0.037|Unlabeled: 0.310]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.20it/s]\n","[Train(  87/  100)-Total: 0.342|Labeled: 0.034|Unlabeled: 0.308]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.30it/s]\n","[Train(  88/  100)-Total: 0.347|Labeled: 0.038|Unlabeled: 0.310]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.31it/s]\n","[Train(  89/  100)-Total: 0.343|Labeled: 0.034|Unlabeled: 0.309]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train(  90/  100)-Total: 0.344|Labeled: 0.036|Unlabeled: 0.308]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.29it/s]\n","[Train(  91/  100)-Total: 0.350|Labeled: 0.037|Unlabeled: 0.313]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.28it/s]\n","[Train(  92/  100)-Total: 0.345|Labeled: 0.037|Unlabeled: 0.309]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.34it/s]\n","[Train(  93/  100)-Total: 0.339|Labeled: 0.037|Unlabeled: 0.303]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.29it/s]\n","[Train(  94/  100)-Total: 0.346|Labeled: 0.037|Unlabeled: 0.309]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.29it/s]\n","[Train(  95/  100)-Total: 0.339|Labeled: 0.036|Unlabeled: 0.303]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.26it/s]\n","[Train(  96/  100)-Total: 0.345|Labeled: 0.037|Unlabeled: 0.308]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.35it/s]\n","[Train(  97/  100)-Total: 0.342|Labeled: 0.036|Unlabeled: 0.306]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.27it/s]\n","[Train(  98/  100)-Total: 0.342|Labeled: 0.034|Unlabeled: 0.308]: 100%|\u001b[94m██████████\u001b[39m| [01:06<00:00, 15.32it/s]\n","[Train(  99/  100)-Total: 0.336|Labeled: 0.034|Unlabeled: 0.302]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.28it/s]\n","[Train( 100/  100)-Total: 0.341|Labeled: 0.037|Unlabeled: 0.304]: 100%|\u001b[94m██████████\u001b[39m| [01:07<00:00, 15.27it/s]\n"]}],"source":["parser = FixMatch_parser()\n","args = parser.parse_args([])\n","args.cuda = torch.device(\"cuda:0\")\n","\n","# args.epochs = math.ceil(args.total_steps/args.eval_step)\n","args.epochs = 100\n","\n","trainer = FixMatchTrainer(args)\n","\n","best_loss = np.inf\n","\n","losses, losses_x, losses_u = [], [], []\n","\n","train_losses, train_top1s, train_top5s = [], [], []\n","val_losses, val_top1s, val_top5s = [], [], []\n","test_losses, test_top1s, test_top5s = [], [], []\n","for epoch in range(1, args.epochs+1, 1):\n","    loss, loss_x, loss_u = trainer.train(epoch)\n","    losses.append(loss)\n","    losses_x.append(loss_x)\n","    losses_u.append(loss_u)\n","\n","    torch.save(trainer.model.state_dict(), os.path.join(trainer.experiment_dir, 'model.pth'))\n","    torch.save(trainer.ema_model.ema.state_dict(), os.path.join(trainer.experiment_dir, 'ema_model.pth'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOlPCugRo71vcLXM5mz4PAo","collapsed_sections":[],"name":"FixMatch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}},"nbformat":4,"nbformat_minor":2}

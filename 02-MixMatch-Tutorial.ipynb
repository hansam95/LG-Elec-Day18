{"cells":[{"cell_type":"markdown","metadata":{},"source":["# MixMatch PyTorch Implementation"]},{"cell_type":"markdown","metadata":{},"source":["## 필요한 패키지 다운로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QFHP0Js1JBSs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (0.4.6)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n","You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install colorama"]},{"cell_type":"markdown","metadata":{},"source":["## 필요한 패키지 중 이미 다운 받아진 패키지 부르기"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"4gCQgfpOHkb7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os, math, sys, argparse\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","from tqdm import tqdm\n","from colorama import Fore\n","from torch.utils.data import DataLoader\n","from torchvision import transforms as transforms\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def Normalize(x, m=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2345, 0.2616)):\n","    # m: mean, std: standard deviation\n","    # (mean, std) 사전에 구해진 값이기에 따로 구할 필요 없음\n","    # MixMatch를 개인적으로 사용하시는 분은 새롭게 구해야 함\n","    # ex: 변수가 10개인 tablur data에 적용한다면, 변수 별 mean, std를 구해주어야함\n","    # from torchvision.transforms 내 Normalize 함수와 동일한 함수\n","    x, m, std = [np.array(a, np.float32) for a in (x, m, std)]\n","\n","    x -= m * 255\n","    x *= 1.0/(255*std)\n","    return x\n","\n","\n","def Transpose(x, source='NHWC', target='NCHW'):\n","    # N, H, W, C = Batch_size, Height, Width, # of channels\n","    # 일반적인 이미지의 경우 3\n","    # torch.nn.Conv2d는 (N, C, H, W) 의 형태를 가진 데이터를 입력 받기 때문에 형태 변경\n","    # from torchvision.transforms 내 ToTensor 와 동일한 함수\n","    return x.transpose([source.index(d) for d in target])\n","\n","\n","def pad(x, border=4):\n","    # 특정 이미지에 동서남북 방향으로 4만큼 픽셀을 추가해 붙여주는 작업\n","    # 이를 padding이라 부름\n","    return np.pad(x, [(0, 0), (border, border), (border, border)], mode='reflect')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7-gtzL_IHmEn"},"outputs":[],"source":["class Transform_Twice:\n","    def __init__(self, transform):\n","        self.transform = transform\n","    \n","    def __call__(self, img):\n","        out1 = self.transform(img)\n","        out2 = self.transform(img)\n","        return out1, out2"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3sOUFnwmHmHc"},"outputs":[],"source":["class Labeled_CIFAR10(torchvision.datasets.CIFAR10):\n","    def __init__(self, root, indices=None,\n","                train=True, transform=None,\n","                target_transform=None, download=False):\n","        super(Labeled_CIFAR10, self).__init__(root,\n","                                        train=train,\n","                                        transform=transform,\n","                                        target_transform=target_transform,\n","                                        download=download)\n","\n","        # label 데이터로 지정된 index\n","        if indices is not None:\n","            self.data = self.data[indices]\n","            self.targets = np.array(self.targets)[indices]\n","        \n","        self.data = Transpose(Normalize(self.data))\n","    \n","    def __getitem__(self, index):\n","        img, target = self.data[index], self.targets[index]\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        \n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","        \n","        return img, target\n","\n"," \n","class Unlabeled_CIFAR10(Labeled_CIFAR10):\n","    def __init__(self, root, indices, train=True, transform=None, target_transform=None, download=False):\n","        super(Unlabeled_CIFAR10, self).__init__(root, indices, train,\n","                                            transform=transform,\n","                                            target_transform=target_transform,\n","                                            download=download)\n","        self.targets = np.array([-1 for i in range(len(self.targets))])"]},{"cell_type":"markdown","metadata":{},"source":["#### '-1' 의 의미: Label이 없는 데이터(Unlabeled data)라 정의"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"PNJw-5pdHmMe"},"outputs":[],"source":["def split_datasets(labels, n_labeled_per_class):\n","    labels = np.array(labels, dtype=int) # list to numpy.ndarray\n","    indice_labeled, indice_unlabeled, indice_val = [], [], [] # labeled, unlabeled, validation data 분할\n","\n","    for i in range(10):\n","        # 클래스별 인덱스\n","        indice_tmp = np.where(labels==i)[0]\n","\n","        # 클래스 내 500개 데이터는 validation data로 정의\n","        # 클래스 당 n_labeled_per_class 개수 만큼 labeled data로 정의\n","        # 나머지 이미지는 unlabeled data로 정의\n","        indice_labeled.extend(indice_tmp[: n_labeled_per_class])\n","        indice_unlabeled.extend(indice_tmp[n_labeled_per_class: -500])\n","        indice_val.extend(indice_tmp[-500: ])\n","    \n","    for i in [indice_labeled, indice_unlabeled, indice_val]:\n","        np.random.shuffle(i)\n","    \n","    return indice_labeled, indice_unlabeled, indice_val"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"45-rzXQKHmPE"},"outputs":[],"source":["def get_cifar10(data_dir: str, n_labeled: int,\n","                transform_train=None, transform_val=None,\n","                download=True):\n","    \n","    # 기본적으로 Torchvision에서 제공해주는 CIFAR10 dataset을 위한 데이터 셋\n","    base_dataset = torchvision.datasets.CIFAR10(data_dir, train=True, download=download)\n","    \n","    # n_labeled는 아래 MixMatch_argparser 함수에서 정의\n","    indice_labeled, indice_unlabeled, indice_val = split_datasets(base_dataset.targets, int(n_labeled/10))\n","\n","    train_labeled_set = Labeled_CIFAR10(data_dir, indice_labeled, train=True, transform=transform_train) # train dataset 내 labeled data load\n","    train_unlabeled_set = Unlabeled_CIFAR10(data_dir, indice_unlabeled, train=True, transform=Transform_Twice(transform_train)) # train dataset 내 unlabeled data load\n","\n","    val_set = Labeled_CIFAR10(data_dir, indice_val, train=True, transform=transform_val, download=True) # validation dataset\n","\n","    test_set = Labeled_CIFAR10(data_dir, train=False, transform=transform_val, download=True) # test dataset\n","\n","    return train_labeled_set, train_unlabeled_set, val_set, test_set"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"lYm7Pt1vHmUL"},"outputs":[],"source":["class RandomPadandCrop(object):\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, (int, tuple))\n","        if isinstance(output_size, int):\n","            self.output_size = (output_size, output_size)\n","        else:\n","            assert len(output_size) == 2\n","            self.output_size = output_size\n","    \n","    def __call__(self, x):\n","        x = pad(x, 4)\n","        \n","        old_h, old_w = x.shape[1: ]\n","        new_h, new_w = self.output_size\n","        \n","        top = np.random.randint(0, old_h-new_h)\n","        left = np.random.randint(0, old_w-new_w)\n","        \n","        x = x[:, top:top+new_h, left:left+new_w]\n","        return x\n","    \n","class RandomFlip(object):\n","    def __call__(self, x):\n","        if np.random.rand() < 0.5:\n","            x = x[:, :, ::-1]\n","        \n","        return x.copy()\n","\n","class ToTensor(object):\n","    def __call__(self, x):\n","        x = torch.from_numpy(x)\n","        return x"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<img src='image/img5.png' width='800'></img>"]},{"cell_type":"markdown","metadata":{},"source":["## WideResNet"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"_a9lgAOhHmeF"},"outputs":[],"source":["class BasicBlock(nn.Module):\n","    def __init__(self, in_planes, out_planes, stride, dropRate=0.0, activate_before_residual=False):\n","        super(BasicBlock, self).__init__()\n","        self.bn1 = nn.BatchNorm2d(in_planes, momentum=0.001)\n","        self.relu1 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n","        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_planes, momentum=0.001)\n","        self.relu2 = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n","        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        self.droprate = dropRate\n","        self.equalInOut = (in_planes == out_planes)\n","        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n","                               padding=0, bias=False) or None\n","        self.activate_before_residual = activate_before_residual\n","    def forward(self, x):\n","        if not self.equalInOut and self.activate_before_residual == True:\n","            x = self.relu1(self.bn1(x))\n","        else:\n","            out = self.relu1(self.bn1(x))\n","        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n","        if self.droprate > 0:\n","            out = F.dropout(out, p=self.droprate, training=self.training)\n","        out = self.conv2(out)\n","        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n","    \n","\n","class NetworkBlock(nn.Module):\n","    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0, activate_before_residual=False):\n","        super(NetworkBlock, self).__init__()\n","        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual)\n","    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate, activate_before_residual):\n","        layers = []\n","        for i in range(int(nb_layers)):\n","            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate, activate_before_residual))\n","        return nn.Sequential(*layers)\n","    def forward(self, x):\n","        return self.layer(x)\n","    \n","\n","class WideResNet(nn.Module):\n","    def __init__(self, num_classes, depth=28, widen_factor=2, dropRate=0.0):\n","        super(WideResNet, self).__init__()\n","        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor] # 채널수\n","        assert((depth - 4) % 6 == 0)\n","        n = (depth - 4) / 6\n","        block = BasicBlock\n","        # 1st conv before any network block\n","        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n","                               padding=1, bias=False)\n","        # 1st block\n","        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate, activate_before_residual=True)\n","        # 2nd block\n","        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n","        # 3rd block\n","        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n","        # global average pooling and classifier\n","        self.bn1 = nn.BatchNorm2d(nChannels[3], momentum=0.001)\n","        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n","        self.fc = nn.Linear(nChannels[3], num_classes)\n","        self.nChannels = nChannels[3]\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                nn.init.xavier_normal_(m.weight.data)\n","                m.bias.data.zero_()\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.block1(out)\n","        out = self.block2(out)\n","        out = self.block3(out)\n","        out = self.relu(self.bn1(out))\n","        out = F.avg_pool2d(out, 8)\n","        out = out.view(-1, self.nChannels)\n","        return self.fc(out)"]},{"cell_type":"markdown","metadata":{},"source":["## Semi-supervised loss function\n","#### Semi-supervised loss = Loss(Labeled, x) + lambda * Loss(Unlabeled, u)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# current가 증가함에 따라 값이 증가\n","def linear_rampup(current, rampup_length):\n","    if rampup_length == 0:\n","        return 1.0\n","    else:\n","        current = np.clip(current/rampup_length, 0.0, 1.0)\n","        return float(current)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"1HxAJDO2IoFA"},"outputs":[],"source":["# 학습이 진행됨에 따라 unlabed data에 대한 가중치 증가\n","class Loss_Semisupervised(object):\n","    def __call__(self, args, outputs_x, target_x, outputs_u, targets_u, epoch):\n","        self.args = args\n","        probs_u = torch.softmax(outputs_u, dim=1)\n","\n","        loss_x = -torch.mean(\n","            torch.sum(F.log_softmax(outputs_x, dim=1)*target_x, dim=1)\n","        )\n","\n","        loss_u = torch.mean((probs_u-targets_u)**2)\n","\n","        return loss_x, loss_u, self.args.lambda_u*linear_rampup(epoch, self.args.epochs)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<img src='image/img6.png' width='800'></img>"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"3KyEyMQPIobG"},"outputs":[],"source":["class WeightEMA(object): # EMA=Exponential Moving Average\n","    def __init__(self, model, ema_model, lr, alpha=0.999):\n","        self.model = model\n","        self.ema_model = ema_model\n","\n","        self.alpha = alpha\n","\n","        self.params = list(self.model.state_dict().items())\n","        self.ema_params = list(self.ema_model.state_dict().items())\n","\n","        self.wd = 0.02 * lr\n","\n","        for param, ema_param in zip(self.params, self.ema_params):\n","            param[1].data.copy_(ema_param[1].data)\n","    \n","    def step(self):\n","        inverse_alpha = 1.0 - self.alpha\n","        for param, ema_param in zip(self.params, self.ema_params):\n","            if ema_param[1].dtype == torch.float32:\n","                ema_param[1].mul_(self.alpha) # ema_params_new = self.alpha * ema_params_old\n","                ema_param[1].add_(param[1]*inverse_alpha) # ema_params_Double_new = (1-self.alpha)*params\n","\n","                # summary: ema_params_new = self.alpha*ema_params_old + (1-self.alpha)*params\n","                # params: 학습되고 있는 모델 parameter\n","                param[1].mul_(1-self.wd)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"qoESnZ41IzOZ"},"outputs":[],"source":["def interleave_offsets(batch_size, nu):\n","    groups = [batch_size//(nu+1)]*(nu+1)\n","    for x in range(batch_size-sum(groups)):\n","        groups[-x-1] += 1\n","\n","    offsets = [0]\n","    for g in groups:\n","        offsets.append(offsets[-1]+g)\n","    \n","    assert offsets[-1] == batch_size\n","    return offsets"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"pW0CqEc7IokG"},"outputs":[],"source":["def interleave(xy, batch_size):\n","    nu = len(xy) - 1\n","    offsets = interleave_offsets(batch_size, nu)\n","\n","    xy = [[v[offsets[p]:offsets[p+1]] for p in range(nu+1)] for v in xy]\n","    for i in range(1, nu+1):\n","        xy[0][i], xy[i][i] = xy[i][i], xy[0][i]\n","    return [torch.cat(v, dim=0) for v in xy]"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"0ekZyGFLI7MS"},"outputs":[],"source":["def get_tqdm_config(total, leave=True, color='white'):\n","    fore_colors = {\n","        'red': Fore.LIGHTRED_EX,\n","        'green': Fore.LIGHTGREEN_EX,\n","        'yellow': Fore.LIGHTYELLOW_EX,\n","        'blue': Fore.LIGHTBLUE_EX,\n","        'magenta': Fore.LIGHTMAGENTA_EX,\n","        'cyan': Fore.LIGHTCYAN_EX,\n","        'white': Fore.LIGHTWHITE_EX,\n","    }\n","    return {\n","        'file': sys.stdout,\n","        'total': total,\n","        'desc': \" \",\n","        'dynamic_ncols': True,\n","        'bar_format':\n","            \"{l_bar}%s{bar}%s| [{elapsed}<{remaining}, {rate_fmt}{postfix}]\" % (fore_colors[color], Fore.RESET),\n","        'leave': leave\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation metric\n","#### top1 accuracy, top5 accuracy\n","#### top1 accuracy: (확률 값이 가장 높은 범주와 실제 범주가 일치하는 관측치 수)/ 전체 관측치\n","#### top5 accuracy: (확률 값 상위 5개 중 실제 범주가 존재하는 관측치 수)/ 전체 관측치"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"6sDCabk8JaGy"},"outputs":[],"source":["def accuracy(output, target, topk=(1, )):\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        if k == 1:\n","            correct_k = correct[:k].view(-1).float().sum(0)\n","        if k > 1:\n","            correct_k = correct[:k].float().sum(0).sum(0)\n","        acc = correct_k.mul_(100.0 / batch_size)\n","        acc = acc.detach().cpu().numpy()\n","        res.append(acc)\n","    return res"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"njMqQgRKH85I"},"outputs":[],"source":["class MixMatchTrainer():\n","    def __init__(self, args):\n","        self.args = args\n","\n","        # root_dir = '/content/MixMatch' # PROJECT directory\n","        root_dir = './MixMatch'\n","        self.experiment_dir = os.path.join(root_dir, 'results') # 학습된 모델을 저장할 폴더 경로 정의 및 폴더 생성\n","        os.makedirs(self.experiment_dir, exist_ok=True)\n","\n","        name_exp = \"_\".join([str(self.args.n_labeled), str(self.args.T)]) # 주요 하이퍼 파라미터로 폴더 저장 경로 지정 \n","        self.experiment_dir = os.path.join(self.experiment_dir, name_exp)\n","        os.makedirs(self.experiment_dir, exist_ok=True)\n","\n","        # Data\n","        print(\"==> Preparing CIFAR10 dataset\")\n","        transform_train = transforms.Compose([\n","            RandomPadandCrop(32),\n","            RandomFlip(),\n","            ToTensor()\n","        ]) # 학습에 사용할 data augmentation 정의\n","\n","        transform_val = transforms.Compose([\n","            ToTensor()\n","        ]) # validation, test dataset에 대한 data augmentation 정의\n","           # 합성곱 신경망에 입력 될 수 있도록만 지정(Augmentation 사용하지 않는 것과 동일)\n","\n","        train_labeled_set, train_unlabeled_set, val_set, test_set = \\\n","            get_cifar10(\n","                data_dir=os.path.join(root_dir, 'data'),\n","                n_labeled=self.args.n_labeled,\n","                transform_train=transform_train,\n","                transform_val=transform_val\n","            ) # 앞에서 정의한 (def) get_cifar10 함수에서 train_labeled, train_unlabeled, validation, test dataset\n","        \n","        # DataLoader 정의\n","        self.labeled_loader = DataLoader(\n","            dataset=train_labeled_set,\n","            batch_size=self.args.batch_size,\n","            shuffle=True, num_workers=0, drop_last=True\n","        )\n","\n","        self.unlabeled_loader = DataLoader(\n","            dataset=train_unlabeled_set,\n","            batch_size=self.args.batch_size,\n","            shuffle=True, num_workers=0, drop_last=True\n","        )\n","\n","        # Build WideResNet\n","        print(\"==> Preparing WideResNet\")\n","        self.model = self.create_model(ema=False)\n","        self.ema_model = self.create_model(ema=True)\n","\n","        # Define loss functions\n","        self.criterion_train = Loss_Semisupervised()\n","        self.criterion_val = nn.CrossEntropyLoss().to(self.args.cuda)\n","\n","        # Define optimizers\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.args.lr)\n","        self.ema_optimizer = WeightEMA(self.model, self.ema_model, lr=self.args.lr, alpha=self.args.ema_decay)\n","\n","        # 학습 결과를 저장할 Tensorboard 정의\n","        self.writer = SummaryWriter(self.experiment_dir)\n","\n","    def create_model(self, ema=False):\n","        # Build WideResNet & EMA model\n","        model = WideResNet(num_classes=10)\n","        model = model.to(self.args.cuda)\n","\n","        if ema:\n","            for param in model.parameters():\n","                param.detach_()\n","            \n","        return model\n","    \n","    def train(self, epoch):\n","        # 모델 학습 함수\n","        losses_t, losses_x, losses_u, ws = 0.0, 0.0, 0.0, 0.0\n","        self.model.train()\n","\n","        # iter & next remind\n","        # iter: list 내 batch size 만큼 랜덤하게 불러오게 하는 함수\n","        # next: iter 함수가 작동하도록 하는 명령어\n","        iter_labeled = iter(self.labeled_loader)\n","        iter_unlabeled = iter(self.unlabeled_loader)\n","\n","        with tqdm(**get_tqdm_config(total=self.args.num_iter,\n","                leave=True, color='blue')) as pbar:\n","            for batch_idx in range(self.args.num_iter):\n","                # 왜 try-except 문을 사용하나?\n","                # 코드 작성 후 iter&next가 정확히 작용하지 않는 경우가 있음을 확인\n","                # 다시 iter_labeled, iter_unlabeled를 정의해 학습에 문제가 없도록 다시 선언\n","                try:\n","                    inputs_x, targets_x = next(iter_labeled)\n","                except:\n","                    iter_labeled = iter(self.labeled_loader)\n","                    inputs_x, targets_x = next(iter_labeled)\n","                real_B = inputs_x.size(0)\n","\n","                # Transform label to one-hot\n","                targets_x = torch.zeros(real_B, 10).scatter_(1, targets_x.view(-1,1).long(), 1)\n","                inputs_x, targets_x = inputs_x.to(self.args.cuda), targets_x.to(self.args.cuda)\n","\n","                try:\n","                    tmp_inputs, _ = next(iter_unlabeled)\n","                except:\n","                    iter_unlabeled = iter(self.unlabeled_loader)\n","                    tmp_inputs, _ = next(iter_unlabeled)\n","\n","                # augmentation (K=2)\n","                inputs_u1, inputs_u2 = tmp_inputs[0], tmp_inputs[1]\n","                inputs_u1, inputs_u2 = inputs_u1.to(self.args.cuda), inputs_u2.to(self.args.cuda)\n","\n","                # Unlabeled data에 대한 실제 값 생성\n","                # 서로 다른 Augmentation 결과의 출력 값의 평균 계산\n","                # Temperature 값으로 실제 값 스케일링\n","                with torch.no_grad():\n","                    outputs_u1 = self.model(inputs_u1)\n","                    outputs_u2 = self.model(inputs_u2)\n","\n","                    pt = (torch.softmax(outputs_u1, dim=1)+torch.softmax(outputs_u2, dim=1)) / 2\n","                    pt = pt**(1/self.args.T) # sharpening\n","\n","                    targets_u = pt / pt.sum(dim=1, keepdim=True)\n","                    targets_u = targets_u.detach()\n","                \n","                # MixUp\n","                # 서로 다른 이미지와 레이블을 섞는 작업\n","                # feature space 상에서 범주 별 Decision boundary를 정확하게 잡아주는 역할\n","                inputs = torch.cat([inputs_x, inputs_u1, inputs_u2], dim=0)\n","                targets = torch.cat([targets_x, targets_u, targets_u], dim=0)\n","\n","                l_mixup = np.random.beta(self.args.alpha, self.args.alpha)\n","                l_mixup = max(l_mixup, 1-l_mixup)\n","\n","                # inputs의 index를 섞어 서로 다른 범주끼리 섞도록 하는 역할\n","                B = inputs.size(0)\n","                random_idx = torch.randperm(B)\n","\n","                inputs_a, inputs_b = inputs, inputs[random_idx]\n","                targets_a, targets_b = targets, targets[random_idx]\n","\n","                mixed_input = l_mixup*inputs_a + (1-l_mixup)*inputs_b\n","                mixed_target = l_mixup*targets_a + (1-l_mixup)*targets_b\n","\n","                # batch norm 연산을 정확히 진행\n","                # batch size 만큼 분할 진행 (2N, C, H, W) -> (N, C, H, W) & (N, C, H, W)\n","                # 앞 부분은 labeled, 뒷 부분은 unlabeled\n","                mixed_input = list(torch.split(mixed_input, real_B))\n","                mixed_input = interleave(mixed_input, real_B)\n","\n","                logits = [self.model(mixed_input[0])] # for labeled\n","                for input in mixed_input[1:]:\n","                    logits.append(self.model(input)) # for unlabeled\n","\n","                logits = interleave(logits, real_B)\n","                logits_x = logits[0]\n","                logits_u = torch.cat(logits[1:], dim=0)\n","\n","                loss_x, loss_u, w = \\\n","                    self.criterion_train(self.args,\n","                                    logits_x, mixed_target[:real_B],\n","                                    logits_u, mixed_target[real_B:],\n","                                    epoch+batch_idx/self.args.num_iter) # Semi-supervised loss 계산\n","\n","                loss = loss_x + w * loss_u\n","\n","                # Backpropagation and Model parameter update\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","                self.ema_optimizer.step()\n","\n","                losses_x += loss_x.item()\n","                losses_u += loss_u.item()\n","                losses_t += loss.item()\n","                ws += w\n","\n","                self.writer.add_scalars(\n","                    'Training steps', {\n","                        'Total_loss': losses_t/(batch_idx+1),\n","                        'Labeled_loss':losses_x/(batch_idx+1),\n","                        'Unlabeled_loss':losses_u/(batch_idx+1),\n","                        'W values': ws/(batch_idx+1)\n","                    }, global_step=epoch*self.args.batch_size+batch_idx\n","                )\n","\n","                pbar.set_description(\n","                    '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n","                        (batch_idx+1), self.args.num_iter,\n","                        losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n","                    )\n","                )\n","                pbar.update(1)\n","\n","            pbar.set_description(\n","                '[Train(%4d/ %4d)-Total: %.3f|Labeled: %.3f|Unlabeled: %.3f]'%(\n","                    epoch, self.args.epochs,\n","                    losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)\n","                )\n","            )\n","        \n","        return losses_t/(batch_idx+1), losses_x/(batch_idx+1), losses_u/(batch_idx+1)"]},{"cell_type":"markdown","metadata":{},"source":["## Define hyperparamters\n","#### argparser라는 패키지를 이용해 각종 hyperparameter 저장"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"wscpGd8NH87k"},"outputs":[],"source":["def MixMatch_parser():\n","    parser = argparse.ArgumentParser(description=\"MixMatch PyTorch Implementation for LG Electornics education\")\n","    \n","    # method arguments\n","    parser.add_argument('--n-labeled', type=int, default=3000)\n","    parser.add_argument('--num-iter', type=int, default=1024,\n","                        help=\"The number of iteration per epoch\")\n","    parser.add_argument('--alpha', type=float, default=0.75)\n","    parser.add_argument('--lambda-u', type=float, default=75)\n","    parser.add_argument('--T', default=0.5, type=float)\n","    parser.add_argument('--ema-decay', type=float, default=0.999)\n","\n","    parser.add_argument('--epochs', type=int, default=100)\n","    parser.add_argument('--batch-size', type=int, default=64)\n","    parser.add_argument('--lr', type=float, default=0.002)\n","\n","    return parser"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZEjxA_eSH896"},"outputs":[],"source":["parser = MixMatch_parser()\n","args = parser.parse_args([])\n","args.cuda = torch.device(\"cuda:0\")\n","\n","trainer = MixMatchTrainer(args)\n","\n","best_loss = np.inf\n","# best_loss of validation 기준으로 모멜 저장\n","\n","losses, losses_x, losses_u = [], [], []\n","\n","train_losses, train_top1s, train_top5s = [], [], []\n","# accuracy 증가 속도, loss values 감소 속도를 그래프로 그리기\n","# list에 각종 값들을 저장\n","for epoch in range(1, args.epochs+1, 1):\n","    loss, loss_x, loss_u = trainer.train(epoch)\n","    losses.append(loss)\n","    losses_x.append(loss_x)\n","    losses_u.append(loss_u)\n","\n","    torch.save(trainer.model.state_dict(), os.path.join(trainer.experiment_dir, 'model.pth'))\n","    torch.save(trainer.ema_model.state_dict(), os.path.join(trainer.experiment_dir, 'ema_model.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPxnUlhDyQQW8m0x4Udibre","collapsed_sections":[],"name":"Untitled1.ipynb","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}},"nbformat":4,"nbformat_minor":2}
